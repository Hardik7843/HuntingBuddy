{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03999639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spacy\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b205550f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the entities and their values\n",
    "entities_values = {\n",
    "    \"CONCEPT\": [\"Data Science\", \"Machine Learning\", \"Deep Learning\", \"Artificial Intelligence\", \"Big Data\", \"Data Mining\", \"Data Analysis\", \"Statistical Analysis\"],\n",
    "    \"CODING LANGUAGES\": [\"Python\", \"R\", \"SQL\"],\n",
    "    \"FRAMEWORKS\": [\"TensorFlow\", \"PyTorch\", \"Scikit-learn\"],\n",
    "    \"TOOLS\": [\"Jupyter Notebook\", \"Anaconda\", \"Git\", \"Docker\", \"AWS\", \"Azure\", \"Google Cloud Platform\"],\n",
    "    \"DATABASES\": [\"MySQL\", \"PostgreSQL\", \"MongoDB\", \"SQLite\"],\n",
    "    \"VISUALIZATION TOOLS\": [\"Matplotlib\", \"Seaborn\", \"Plotly\", \"Tableau\"],\n",
    "    \"EXPERIENCE\": [\"0-2 years\", \"2-5 years\", \"5+ years\"],\n",
    "    \"DEGREE\": [\"Computer Science\", \"Statistics\", \"Mathematics\", \"Data Science\", \"Engineering\"],\n",
    "    \"CERTIFICATIONS\": [\"Data Science Certification\", \"Machine Learning Certification\", \"AWS Certification\", \"Azure Certification\"],\n",
    "    \"SOFT SKILLS\": [\"Analytical Thinking\", \"Problem-solving\", \"Communication\", \"Teamwork\"],\n",
    "    \"DOMAIN KNOWLEDGE\": [\"Finance\", \"Healthcare\", \"E-commerce\", \"Marketing\"],\n",
    "    \"PROJECTS\": [\"Predictive Modeling\", \"Natural Language Processing\", \"Computer Vision\", \"Time Series Analysis\"],\n",
    "    \"PUBLICATIONS\": [\"Research Papers\", \"Conference Presentations\", \"Technical Blog Posts\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ed87431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular expression for experience levels\n",
    "experience_pattern = r\"\\b(\\d+\\s*(?:years|yrs?))\\b\"\n",
    "\n",
    "# Load a blank English model\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Define the entity recognizer with the ner pipeline component\n",
    "ner = nlp.add_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6868d28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Data Science', 'Machine Learning', 'Deep Learning', 'Artificial Intelligence', 'Big Data', 'Data Mining', 'Data Analysis', 'Statistical Analysis'], ['Python', 'R', 'SQL'], ['TensorFlow', 'PyTorch', 'Scikit-learn'], ['Jupyter Notebook', 'Anaconda', 'Git', 'Docker', 'AWS', 'Azure', 'Google Cloud Platform'], ['MySQL', 'PostgreSQL', 'MongoDB', 'SQLite'], ['Matplotlib', 'Seaborn', 'Plotly', 'Tableau'], ['0-2 years', '2-5 years', '5+ years'], ['Computer Science', 'Statistics', 'Mathematics', 'Data Science', 'Engineering'], ['Data Science Certification', 'Machine Learning Certification', 'AWS Certification', 'Azure Certification'], ['Analytical Thinking', 'Problem-solving', 'Communication', 'Teamwork'], ['Finance', 'Healthcare', 'E-commerce', 'Marketing'], ['Predictive Modeling', 'Natural Language Processing', 'Computer Vision', 'Time Series Analysis'], ['Research Papers', 'Conference Presentations', 'Technical Blog Posts']]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "[E978] The Parser.initialize method takes a list of Example objects, but got: {<class 'list'>}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m: [entities_values[label] \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m entities_values]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(x())\n\u001b[1;32m----> 3\u001b[0m \u001b[43mner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hardi\\OneDrive\\Desktop\\Hardik stuff\\HuntingBuddy\\buddy\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:565\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.initialize\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\hardi\\OneDrive\\Desktop\\Hardik stuff\\HuntingBuddy\\buddy\\lib\\site-packages\\spacy\\training\\example.pyx:75\u001b[0m, in \u001b[0;36mspacy.training.example.validate_get_examples\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\hardi\\OneDrive\\Desktop\\Hardik stuff\\HuntingBuddy\\buddy\\lib\\site-packages\\spacy\\training\\example.pyx:57\u001b[0m, in \u001b[0;36mspacy.training.example.validate_examples\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: [E978] The Parser.initialize method takes a list of Example objects, but got: {<class 'list'>}"
     ]
    }
   ],
   "source": [
    "x = lambda: [entities_values[label] for label in entities_values]\n",
    "print(x())\n",
    "ner.initialize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70294dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the labels to the entity recognizer\n",
    "for label, values in entities_values.items():\n",
    "    ner.add_label(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f02dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing sample data\n",
    "sample_data_dir = r\"sample data\"\n",
    "\n",
    "# Define a list to store annotated data\n",
    "annotated_data = []\n",
    "\n",
    "# Process each file in the sample data directory\n",
    "for file_name in os.listdir(sample_data_dir):\n",
    "    # Read the text from the file\n",
    "    with open(os.path.join(sample_data_dir, file_name), \"r\") as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    # Create a Doc object from the text\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Extract annotated entities and store in JSON format\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        entities.append({\n",
    "            \"text\": ent.text,\n",
    "            \"start_char\": ent.start_char,\n",
    "            \"end_char\": ent.end_char,\n",
    "            \"label\": ent.label_\n",
    "        })\n",
    "    \n",
    "    # Add experience levels extracted using regular expression\n",
    "    for match in re.finditer(experience_pattern, text):\n",
    "        entities.append({\n",
    "            \"text\": match.group(1),\n",
    "            \"start_char\": match.start(),\n",
    "            \"end_char\": match.end(),\n",
    "            \"label\": \"EXPERIENCE\"\n",
    "        })\n",
    "    \n",
    "    annotated_data.append({\"text\": text, \"entities\": entities})\n",
    "\n",
    "# Save the annotated data to a JSON file\n",
    "output_file = \"annotated_data.json\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(annotated_data, f, indent=4)\n",
    "\n",
    "print(f\"Annotated data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df3091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beb86f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b8de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2fb8a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c006b24d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a81de8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4453072e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ca2b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3ffe7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d1ae71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7562fe8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e6c460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63005291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8de2a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604534c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0c383f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba39d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bdd3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fbecb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4b0e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a48190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8396eb2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87252088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315af941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159fdcf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "buddy",
   "language": "python",
   "name": "buddy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
